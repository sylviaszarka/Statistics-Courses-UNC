---
title: "Final"
output: html_document
---
```{r setup, include=TR8E}
knitr::opts_chunk$set(echo = TRUE)
library(faraway)
library(dplyr)
library(tidyr)
library(lme4)
library(lattice)
library(RLRsim)
library(pbkrtest)
library(ggplot2)
library(MASS)
library(geepack)

```
##Question 1
1. A "round robin" study is one where the same experiment is performed by a number of different labs, in order to assess how well the different labs are able to reproduce each others' work. As part of such a study, seven labs are asked to conduct tensile strength measurements on samples of steel wire. In total, 44 such measurements are made. The file RoundRobin.csv contains the raw data, which are summarize in Table 1.
```{r}
rr=read.csv('/Users/SylviaSzarka/Desktop/School/STOR 590/FINAL/RoundRobin.csv')
```

(a) Fit a simple linear regression model with Strength as the response and Lab as a predictor. Is the Lab effect statistically significant? [3 points]
```{r}
slr<-lm(Strength~factor(Lab),rr)
summary(slr)
#Out of the 7 labs, 2 of them are statistically significant - Lab A (the intercept in the model, and lab F).
```

(b) Are there any outliers in the data? Use standard diagnostics to determine which (if any) observations might be outliers, giving your reasons. Rerun the analysis without the suspected outliers and state any changes from your conclusions in (a). [3 points]
```{r}
plot(slr)
#points 1, 2, and 37 appear to be outliers on the Residual v. Fitted & normal Q-Q plot.
slromit<-lm(Strength~factor(Lab),rr,subset=c(-1,-2,-37))
summary(slromit)
plot(slromit)
```

(c) Now run this as a random effects regression using lme4, without removing the outlier. State the estimated standard deviations for both the Lab effect and the residual, and calculate a 95% confidence interval for each. [6 points]
**each what? Lab & Residual effect?**
```{r}
rr$Lab<-as.factor(rr$Lab)
##Does it need to be treating each Lab as a separate effect>? That would mean fixed effectll,,? fuckkkKK
rer<-lmer(Strength~1+(1|Lab),rr)
summary(rer)
#95% confidence interval
confint(rer)
#for each?
```
The standard deviation for the Lab effect is 5.051, while the standard deviation for the residual is 11.144. 

(d) Draw a lattice plot to show the means and confidence intervals for the seven lab effects. [4 points]
```{r}
dotplot(ranef(rer,condVar=TRUE))

```

(e) Now run this as a Bayesian analysis using either STAN or INLA (your choice!). Fit a suitable model for a one-way analysis of variance, and show the following:
  i. A plot of posterior densities for the Lab and Residual standard deviations; [3 points]
  ii. A plot of posterior densities for the seven Lab effects; [3 points]
  iii. A summary table of posterior distributions for the main parameters of the models. [4 points]
  
(f) Briefly compare your results from parts (c) and (e). What are the main similarities, and what are the main differences, between the two approaches? [3 points]

(g) Now repeat parts (c) and (e) removing the outlier. There is no need to repeat every part of the analysis, but summarize the most important ways in which the analysis changes when the outlier is omitted. [4 points]
-------------------------------------------------------------------------------------
##Question 2
2. Five varieties of barley were planted in six different fields over two years | see Table 2. The data (in a form suitable for analysis in R) are contained within the file barley.csv.
```{r}
barley=read.csv('/Users/SylviaSzarka/Desktop/School/STOR 590/FINAL/barley.csv')
```

(a) Analyze the data as a fixed effects analysis of variance, treating "Yield" as the response. Are each of the Variety, Field and Year effects statistically significant? Are there significant interactions among any two of the three variables? Briefly summarize your conclusions. [5 points]
```{r}
fmod<- aov(Yield~Variety+Field+Year,barley)
summary(fmod)
#Testing Interactions: *is there a diff way
fmod1<-aov(Yield~Variety*Field+Year,barley)
fmod2<-aov(Yield~Variety*Year+Field,barley)
fmod3<-aov(Yield~Year*Field+Variety,barley)
```
The field and year effects are statistically significant, but the Variety variable is not.

(b) The experimenter is ultimately interested in differentiating different varieties of barley, whereas the Field and Year influences are random. Therefore, we would like reanalyze the data treating Variety as a fixed effect and the other two effects as random. Consider the following variants on a random effects model:
  i. Treat Year as a random effect and ignore Field;
  ii. Treat both Year and Field as separate random effects;   
  iii. Treat both Year and Field as random effects but with Year nested within Field.
Fit each of these three models and briefly summarize the results. Explain, in words, the motivation for preferring either of models (ii) or (iii) over model (i) (no formal testing is required at this stage -- that comes later.) [6 points]
```{r}
op <- options(contrasts=c("contr.sum", "contr.poly"))
options(op)
#dunno if that is needed ^
#i. Year as a random effect and ignore Field;
mmod1<-lmer(Yield~Variety+(1|Year),barley)
#ii. Treat both Year and Field as separate random effects;
mmod2<-lmer(Yield~Variety+(1|Year)+(1|Field),barley)
#iii. Treat both Year and Field as random effects but with Year nested within Field.
mmod3<-lmer(Yield~Variety+(1|Year)+(1|Field:Year),barley)
  #iii.2 another option:
mmod4<-lmer(Yield~Variety+(1|Year)+(1|Field)+(1|Field:Year),barley)
#do i need to add (1|Field) as well as the nested factor^^?
summary(mmod1)
#s.d. for mmod1 is higher than the other models
summary(mmod2)
summary(mmod3)
summary(mmod4)

```
  
(c) For each of models (i), (ii), (iii), refit the model without Variety and perform a Kenward- Roger test for significance of the Variety effect. Why do the three models not all give the same answer? [5 points]
```{r}
#i. Year as a random effect and ignore Field;
mmodi<-lmer(Yield~1+(1|Year),barley)
#testing for Variety effect:
KRmodcomp(mmod1,mmodi)
#ii. Treat both Year and Field as separate random effects;
mmodii<-lmer(Yield~1+(1|Year)+(1|Field),barley)
KRmodcomp(mmod2,mmodii)

#iii. Treat both Year and Field as random effects but with Year nested within Field.
mmodiii<-lmer(Yield~1+(1|Year)+(1|Field:Year),barley)
KRmodcomp(mmod3,mmodiii)

```
In part (i), the Variety effect is not significant with a p-value of 0.106. In part (ii), the Variety effect is quite significant with a p-value of 0.0035. The KR test in part (iii) also produced a highly significant p-value, suggesting that the Variety effect is significant for that model.
They most likely give different answers because part (i) completely ignores the Field effect, which might have an effect on the significance of the Variety effect.
***Elaborate on this***

(d) Now conduct a formal test of model (i) against model (ii) against model (iii) using either a parametric bootstrap or the exactRLRT procedure. After conducting these tests, which of the three models do you prefer? [6 points]
**How to do exactRLRT for the mmod2 and mmod3?**
```{r}
#Only the alternative model needs to specified as there is only one random effect component for 1st  model:

#mmod3: alternative
exactRLRT(mmod2,mmod3,mmod1)
#p-value = 1e-04
exactRLRT(mmod1,mmod3,mmod2)
#p-value < 2.2e-16

#mmod2 alternative
exactRLRT(mmod3,mmod2,mmod1)
#p-value < 2.2e-16

#would PBmodcomp work for parametric bootstrap test?
```

(e) Using model (iii) including the Variety effect, carry out some suitable diagnostic procedures to determine whether the model fits the data. Summarise your conclusions. [5 points]
```{r}
qqnorm(residuals(mmod3))
plot(fitted(mmod3),residuals(mmod3),xlab="fitted",ylab="residuals")
abline(h=0)
```

(f) From the raw data, it looks as though Trebi is the best variety (in the sense of maximizing expected yield) and Field 2 is the best field. For the next year's crop, suppose we plant Trebi in either (i) Field 2, or (ii) some randomly chosen new field. For each of (i) and (ii), give a point prediction and a 95% prediction interval for the yield of the new crop. Assume model (iii) from part (b). [6 points]

-------------------------------------------------------------------------------------
##Question 3:
##*Chp 13*
3. A study was conducted in which 167 mothers with children were asked to provide demographic and personal information and then followed up for 28 days each. On each day, the mother was assessed for stress and a binary variable stress (0 for low stress. 1 for high stress) was recorded. The covariates involved in the study were:
  id = mother-child id
  day = study day t=(1,2,...,28)
  stress = maternal stress at day(t): 1=yes, 0=no
  married = marital status: 1=married, 0=other
  education = highest educational level: 1=less than high school, 2=some high school, 3=high school graduate, 4=some college,        5=college graduate
  employed = employment status: 1=employed, 0=unemployed
  chlth = child health status at baseline: 1=very poor, 2=poor, 3=fair, 4=good, 5=very good
  mhlth = mother health status at baseline: 1=very poor, 2=poor, 3=fair, 4=good, 5=very good
  race = child race: 1=non-white, 0=white
  csex = child gender: 1=male, 2=female
  housize = size of household:  1=more than 3 people, 0=2-3 people
```{r}
stress=read.csv('/Users/SylviaSzarka/Desktop/School/STOR 590/FINAL/stress.csv')
```

(a) Construct a plot in which "mean stress level" is plotted against "day," averaging over individuals, with employed and unemployed mothers shown with different plotting symbols on the same plot. Also fit a straight line to the plot, separately for employed and unemployed mothers. You should observe that both groups show decreased stress levels over time, but that the relationship is not the same for the employed and unemployed mothers. Describe the relationships. [7 points]
```{r}
#33 NA values in stress..Do we need to omit? Is it ok to omit these 33 datapoints?
sum(is.na(stress))
stress[is.na(stress$stress),]
stress1<-na.omit(stress)
#Check: Does mother employed status change? -> No. 
length(unique(stress$id))
nrow(unique(stress[,c('id','employed')]))
#Grouping
df <- stress1 %>% 
    group_by(day,employed) %>% 
    summarise(meanstress = mean(stress), emp=mean(employed))
df$employed <- ifelse(df$employed == 1, "Employed", "Unemployed")
#this is averaging based on mean stress levels over the 28 days for unemployed & employed separately -> is that correct?
ggplot(df,aes(x=day,y=meanstress,shape=employed,color=employed)) +geom_point()+geom_line()
ggplot(df,aes(x=day,y=meanstress,shape=employed,color=employed)) +geom_point()+geom_smooth(method="lm")
```

(b) The other variables in the analysis are likely to be correlated with the mother's employment status, and therefore could be confounders to the relationship you observed in (a). With this in mind, fit a GLMM to the whole of the data, including all of day, married, factor(education), employed, factor(chlth), factor(mhlth), race, csex and housize as covariates, but also including a day:employed interaction term. Do this using:
  i. PQL method,
  ii. glmer method,
  iii.GEE method with corstr='ar1'
  iv. GEE method with corstr='exchangeable'
Compare these methods, with particular focus on the statistical significance of the day:employed interaction term. Which method or methods do you think work best for this problem? [12 points]
**How should day:employed interaction be included?** 
**Something seems wrong with ii.**
```{r}
#i. PQL method
modpql=glmmPQL(stress~day*employed+day+married+factor(education)+employed+factor(chlth)+factor(mhlth)+race+csex+housize,random=~1|id,family=binomial,data=stress1)

#ii. glmer method
  #a) using Gauss-Hermite Approach
  modgh=glmer(stress~day+married+factor(education)+employed+factor(chlth)+factor(mhlth)+race+csex+housize+I(day*employed)+(1|id),nAGQ=25,binomial,data=stress1)
       #Model failed to converge with max|grad| = 0.0723041 (tol = 0.002, component 1)
  
  #b) using Laplace Approx., default for glmer
  modlap=glmer(stress~day+married+factor(education)+employed+factor(chlth)+factor(mhlth)+race+csex+housize+I(day*employed)+(1|id),binomial,data=stress1)
       #Error MSG: Model failed to converge with max|grad| = 0.492907;Model is nearly unidentifiable: very large eigenvalue              Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
  
#iii. GEE method with corstr='ar1'
modgeep1=geeglm(stress~day+married+factor(education)+employed+factor(chlth)+factor(mhlth)+race+csex+housize+I(day*employed),id=id,corstr='ar1',scale.fix=T,data=stress1,family=binomial)

#iv. GEE method with corstr='exchangeable'
modgeep2=geeglm(stress~day+married+factor(education)+employed+factor(chlth)+factor(mhlth)+race+csex+housize+I(day*employed),id=id,corstr='exchangeable',scale.fix=T,data=stress1,family=binomial)


```

(c) For your preferred method in (b), investigate whether any of the terms may be dropped from the model, and whether they affect the day:employed interaction. Which model do you choose overall as best? [10 points]

(d) State, in words, a summary of your conclusions. In particular, comment on whether the pattern of stress are different in employed compared with unemployed mothers, and how your conclusions may be affected by the other variables in the analysis. [5 points]




